{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_1 = [i for i in range(1,101)]\n",
    "tweet_2 = [i for i in range(1,101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_1)\n",
    "print(tweet_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = [\",\".join(map(str, comb)) for comb in combinations(tweet_1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combination)\n",
    "len(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination[4949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df = pd.read_csv('tweet_vs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combination_df.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_combination in combination:\n",
    "    split = each_combination.split(',')\n",
    "    combination_df = combination_df.append({\n",
    "        \"tweet_1\": split[0],\n",
    "        \"tweet_2\": split[1]\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df['combination_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df.to_csv('tweet_vs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_df.drop('tweet_1\\ttweet_2',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each_combination in combination:\n",
    "#    print(each_combination[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pulling tweets by username\n",
    "import tweepy\n",
    "import datetime\n",
    "\n",
    "consumer_key        = 'yMsX27Q8WWj5jg2MFLKVsJnxw'\n",
    "consumer_secret     = 'QJ7rmYKoogzBX960D0Letv7XQPh7ri76p4IES8u7jVoVy5QgOq'\n",
    "access_token_key    = '870331200832929793-UuZTn0kEg9vi57f3CXdxQ7AG4LTj6s4'\n",
    "access_token_secret = 'aCeB7T70FzXszxxeoGYAM5ErPQjZITfMUYK8FACopHMBI'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token_key, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "username = '@jokesuk'\n",
    "startDate = datetime.datetime(2021, 6, 1, 0, 0, 0)\n",
    "endDate =   datetime.datetime(2021, 7, 1, 0, 0, 0)\n",
    "\n",
    "tweets = []\n",
    "tmpTweets = api.user_timeline(username)\n",
    "\n",
    "    \"\"\"\n",
    "    for tweet in tmpTweets:\n",
    "    if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "        tweets.append(tweet)\n",
    "\n",
    "while (tmpTweets[-1].created_at > startDate):\n",
    "    tmpTweets = api.user_timeline(username, max_id = tmpTweets[-1].id)\n",
    "    for tweet in tmpTweets:\n",
    "        if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "            tweets.append(tweet)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tmpTweets:\n",
    "    if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "        print(tweet)\n",
    "        tweets.append(tweet)\n",
    "\n",
    "while (tmpTweets[-1].created_at > startDate):\n",
    "    tmpTweets = api.user_timeline(username, max_id = tmpTweets[-1].id)\n",
    "    for tweet in tmpTweets:\n",
    "        if tweet.created_at < endDate and tweet.created_at > startDate:\n",
    "            tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    # Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    consumer_key        = 'yMsX27Q8WWj5jg2MFLKVsJnxw'\n",
    "    consumer_secret     = 'QJ7rmYKoogzBX960D0Letv7XQPh7ri76p4IES8u7jVoVy5QgOq'\n",
    "    access_token_key    = '870331200832929793-UuZTn0kEg9vi57f3CXdxQ7AG4LTj6s4'\n",
    "    access_token_secret = 'aCeB7T70FzXszxxeoGYAM5ErPQjZITfMUYK8FACopHMBI'\n",
    "\n",
    "    # authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token_key, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    # make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=100)\n",
    "\n",
    "    # save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    # save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    # keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print\n",
    "        \"getting tweets before %s\" % (oldest)\n",
    "\n",
    "        # all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name, count=100, max_id=oldest, include_entities=True,\n",
    "                                       tweet_mode='extended')\n",
    "\n",
    "        # save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        # update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print\n",
    "        \"...%s tweets downloaded so far\" % (len(alltweets))\n",
    "\n",
    "    user = api.get_user(screen_name)\n",
    "    followers_count = user.followers_count\n",
    "\n",
    "    # transform the tweepy tweets into a 2D array that will populate the csv\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.full_text.encode(\"utf-8\"), 1 if 'media' in tweet.entities else 0,\n",
    "                  1 if tweet.entities.get('hashtags') else 0, followers_count, tweet.retweet_count, tweet.favorite_count]\n",
    "                 for tweet in alltweets]\n",
    "\n",
    "\n",
    "    # write the csv\n",
    "    with open('tweetsv2.csv', mode='a', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\", \"created_at\", \"text\", \"hasMedia\", \"hasHashtag\", \"followers_count\", \"retweet_count\", \"favourite_count\"])\n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "    pass\n",
    "\n",
    "#status = tweet if 'extended_tweet' in status._json: status_json = status._json['extended_tweet']['full_text'] elif 'retweeted_status' in status._json and 'extended_tweet' in status._json['retweeted_status']: status_json = status._json['retweeted_status']['extended_tweet']['full_text'] elif 'retweeted_status' in status._json: status_json = status._json['retweeted_status']['full_text'] else: status_json = status._json['full_text'] print(status_json)'\n",
    "\n",
    "def main():\n",
    "    get_all_tweets(\"@jokesuk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"I like to have my python script print a message at the beginning. This helps me confirm whether everything is set up correctly. And it's nice to get an uplifting message ;).\"\"\"\n",
    "\n",
    "print(\"You got this!\")\n",
    "\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "tweets = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "\"\"\"Twitter will automatically sample the last 7 days of data. Depending on how many total tweets there are with the specific hashtag, keyword, handle, or key phrase that you are looking for, you can set the date back further by adding since= as one of the parameters. You can also manually add in the number of tweets you want to get back in the items() section.\"\"\"\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search, q=\"@jokesuk\", count=100, since='2020-02-28').items(50000):\n",
    "\t\n",
    "\tprint(count)\n",
    "\tcount += 1\n",
    "\n",
    "\ttry: \n",
    "\t\tdata = [tweet.created_at, tweet.id, tweet.text, tweet.user._json['screen_name'], tweet.user._json['name'], tweet.user._json['created_at'], tweet.entities['urls']]\n",
    "\t\tdata = tuple(data)\n",
    "\t\ttweets.append(data)\n",
    "\n",
    "\texcept tweepy.TweepError as e:\n",
    "\t\tprint(e.reason)\n",
    "\t\tcontinue\n",
    "\n",
    "\texcept StopIteration:\n",
    "\t\tbreak\n",
    "\n",
    "df = pd.DataFrame(tweets, columns = ['created_at','tweet_id', 'tweet_text', 'screen_name', 'name', 'account_creation_date', 'urls'])\n",
    "\n",
    "\"\"\"Add the path to the folder you want to save the CSV file in as well as what you want the CSV file to be named inside the single quotations\"\"\"\n",
    "df.to_csv(path_or_buf = '/Users/Name/Desktop/FolderName/FileName.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method to use!!!\n",
    "### needs a tidy up though\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"I like to have my python script print a message at the beginning. This helps me confirm whether everything is set up correctly. And it's nice to get an uplifting message ;).\"\"\"\n",
    "\n",
    "print(\"You got this!\")\n",
    "\n",
    "consumer_key        = 'yMsX27Q8WWj5jg2MFLKVsJnxw'\n",
    "consumer_secret     = 'QJ7rmYKoogzBX960D0Letv7XQPh7ri76p4IES8u7jVoVy5QgOq'\n",
    "access_token_key    = '870331200832929793-UuZTn0kEg9vi57f3CXdxQ7AG4LTj6s4'\n",
    "access_token_secret = 'aCeB7T70FzXszxxeoGYAM5ErPQjZITfMUYK8FACopHMBI'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token_key, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "tweets = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "\"\"\"Twitter will automatically sample the last 7 days of data. Depending on how many total tweets there are with the specific hashtag, keyword, handle, or key phrase that you are looking for, you can set the date back further by adding since= as one of the parameters. You can also manually add in the number of tweets you want to get back in the items() section.\"\"\"\n",
    "\n",
    "for tweet in tweepy.Cursor(api.user_timeline, id=\"@jokesuk\", count=100, since='2020-02-28', tweet_mode='extended').items(100):\n",
    "\t\n",
    "\tprint(count)\n",
    "\tcount += 1\n",
    "\n",
    "\ttry: \n",
    "\t\tdata = [tweet.created_at, count-1, tweet.full_text, tweet.user._json['screen_name'], tweet.user._json['name'], tweet.user._json['created_at'], tweet.entities['urls']] #changed second value from tweet.id to count\n",
    "\t\tdata = tuple(data)\n",
    "\t\ttweets.append(data)\n",
    "\n",
    "\texcept tweepy.TweepError as e:\n",
    "\t\tprint(e.reason)\n",
    "\t\tcontinue\n",
    "\n",
    "\texcept StopIteration:\n",
    "\t\tbreak\n",
    "\n",
    "df = pd.DataFrame(tweets, columns = ['created_at','tweet_id', 'tweet_text', 'screen_name', 'name', 'account_creation_date', 'urls'])\n",
    "\n",
    "\"\"\"Add the path to the folder you want to save the CSV file in as well as what you want the CSV file to be named inside the single quotations\"\"\"\n",
    "df.to_csv(path_or_buf = 'tweetsv2.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "consumer_key        = 'yMsX27Q8WWj5jg2MFLKVsJnxw'\n",
    "consumer_secret     = 'QJ7rmYKoogzBX960D0Letv7XQPh7ri76p4IES8u7jVoVy5QgOq'\n",
    "access_token_key    = '870331200832929793-UuZTn0kEg9vi57f3CXdxQ7AG4LTj6s4'\n",
    "access_token_secret = 'aCeB7T70FzXszxxeoGYAM5ErPQjZITfMUYK8FACopHMBI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key, consumer_secret, access_token_key, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = '@jokesuk'\n",
    "tweets = api.GetSearch(term=search_term, count=101)\n",
    "print(\"Fetched :\" + str(len(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "tweet_df = pd.DataFrame()\n",
    "for tweet in tweets:\n",
    "    print(\"Printing Tweet[\" + str(i) + \"]:\")\n",
    "    tdict = tweet.AsDict()\n",
    "    tdict['id'] = int(i + 1)\n",
    "    tweet_df = tweet_df.append(tdict, ignore_index=True)\n",
    "    print(tdict['created_at'])\n",
    "    print(tdict['text'])\n",
    "    print('\\n')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.astype({'id': 'int32'})\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.drop(columns=['created_at','hashtags','id_str','in_reply_to_screen_name','in_reply_to_status_id','in_reply_to_user_id','lang','source','urls','user','user_mentions','retweeted_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv(\"tweets_collection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mimic pulling tweets from csv in web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in tweets from CSV\n",
    "tweets = pd.read_csv('tweetsv2.csv')\n",
    "\n",
    "# Pull in combinations\n",
    "combinations = pd.read_csv('tweet_vs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim to pull tweets in based on the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_1 tweet_2\n",
      "0        1       2\n"
     ]
    }
   ],
   "source": [
    "tweets_compared = combinations.loc[[(0)]]\n",
    "\n",
    "print(tweets_compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_compared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tweet1 = tweets_compared.iloc[0]['tweet_1']\n",
    "tweet2 = tweets_compared.iloc[0]['tweet_2']\n",
    "print(tweet1)\n",
    "print(tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @jokesuk: Now that the barbers have reopened, the queues are so long that the staff have started handing out burgers and sausages...\n",
      "\n",
      "De…\n"
     ]
    }
   ],
   "source": [
    "tweet1_display = tweets['tweet_text'].loc[tweets['tweet_id']==tweet1]\n",
    "tweet1_display = tweet1_display.iloc[0]\n",
    "print(tweet1_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "RT @jokesuk: I went into the corner shop to get some helicopter flavoured crisps.\n",
      "\n",
      "The shopkeeper said, \"Sorry we only have plane!\"\n"
     ]
    }
   ],
   "source": [
    "print(tweet2)\n",
    "tweet2_display = tweets['tweet_text'].loc[tweets['tweet_id']==np.int64(tweet2)]\n",
    "tweet2_display = tweet2_display.iloc[0]\n",
    "print(tweet2_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code tidy up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get__tweet_text(id, all_tweet):\n",
    "    tweet_text= all_tweet['tweet_text'].loc[all_tweet['tweet_id']==np.int64(id)]\n",
    "    tweet_text = tweet_text.iloc[0]\n",
    "    \n",
    "    return tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @jokesuk: Now that the barbers have reopened, the queues are so long that the staff have started handing out burgers and sausages...\n",
      "\n",
      "De…\n"
     ]
    }
   ],
   "source": [
    "tweet1_text = get__tweet_text(tweet1, tweets)\n",
    "\n",
    "print(tweet1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparing_tweets_id(tweets_df, location):\n",
    "    tweets_compared = tweets_df.loc[[(location)]]\n",
    "    tweet1 = tweets_compared.iloc[0]['tweet_1']\n",
    "    tweet2 = tweets_compared.iloc[0]['tweet_2']\n",
    "    \n",
    "    return int(tweet1), int(tweet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tweet, second_tweet = get_comparing_tweets_id(combinations, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(first_tweet)\n",
    "print(second_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tweet_text = get__tweet_text(second_tweet, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @jokesuk: My wife caught me in bed with the neighbour.\n",
      "\n",
      "\"It's not as bad as it looks love, honest!\" I said.\n",
      "\n",
      "\"Oh yeah?!\" she shouted. \"J…\n"
     ]
    }
   ],
   "source": [
    "print(next_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
